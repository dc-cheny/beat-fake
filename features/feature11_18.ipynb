{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"shape_predictor_194_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下特征皆用标准差度量：\n",
    " - 嘴唇厚度\n",
    " - 嘴唇宽度\n",
    " - 左右眉毛长度\n",
    " - 鼻翼宽度\n",
    " - 眼睛长度\n",
    " - 眼睛高度\n",
    " - 鼻子中心到上唇中心的距离\n",
    " - 下唇中心到下颚中心的距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十一：嘴唇厚度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.169456234838059\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为lip_thickness\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "each_lip_thickness = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    thickness = []\n",
    "    each_thickness=[]\n",
    "    up_lip_feature=[element for element in range(152,166)]+[element for element in range(180,194)]\n",
    "    low_lip_feature=[element for element in range(11,26)]+[element for element in range(166,180)]\n",
    "    low_lip_feature.remove(22)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        for i in range(14):\n",
    "            each_thickness.append(np.linalg.norm(np.concatenate((shape[up_lip_feature[i]],shape[up_lip_feature[-i-1]])).mean(axis=0)))\n",
    "            each_thickness.append(np.linalg.norm(np.concatenate((shape[low_lip_feature[i]],shape[low_lip_feature[-i-1]])).mean(axis=0)))\n",
    "        thickness.append(np.mean(each_thickness))\n",
    "        \n",
    "    each_lip_thickness.append(thickness)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "each_lip_thickness = np.array(each_lip_thickness)\n",
    "lip_thickness = 0\n",
    "for i in range(len(rects)):\n",
    "    lip_thickness += each_lip_thickness[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "lip_thickness = lip_thickness/len(rects)\n",
    "print(lip_thickness)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十二：嘴唇宽度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7859049317134317\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为lip_width\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "lip_widthDis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        dis.append((np.linalg.norm(shape[152]-shape[165])+np.linalg.norm(shape[180]-shape[193])+np.linalg.norm(shape[25]-shape[11])+np.linalg.norm(shape[166]-shape[179]))/4)\n",
    "        \n",
    "    lip_widthDis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "lip_widthDis = np.array(lip_widthDis)\n",
    "lip_width = 0\n",
    "for i in range(len(rects)):\n",
    "    lip_width += lip_widthDis[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "lip_width = lip_width/len(rects)\n",
    "print(lip_width)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十三：左右眉毛长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3356261127161377\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为brow_width\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "brow_widthDis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        dis.append((np.linalg.norm(shape[92]-shape[102])+np.linalg.norm(shape[103]-shape[113]))/2)\n",
    "        dis.append((np.linalg.norm(shape[70]-shape[80])+np.linalg.norm(shape[81]-shape[91]))/2)\n",
    "    brow_widthDis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "brow_widthDis = np.array(brow_widthDis)\n",
    "brow_width = 0\n",
    "for i in range(len(rects)):\n",
    "    brow_width += brow_widthDis[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "brow_width = brow_width/len(rects)\n",
    "print(brow_width)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十四：鼻子宽度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1836923968257231\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为nose_width\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "nose_widthDis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        dis.append(np.linalg.norm(shape[139]-shape[147]))\n",
    "    nose_widthDis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "nose_widthDis = np.array(nose_widthDis)\n",
    "nose_width = 0\n",
    "for i in range(len(rects)):\n",
    "    nose_width += nose_widthDis[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "nose_width = nose_width/len(rects)\n",
    "print(nose_width)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十五：眼睛长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795376768829515\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为eye_width\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "eye_widthDis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        dis.append((np.linalg.norm(shape[48]-shape[58])+np.linalg.norm(shape[59]-shape[69]))/2)\n",
    "        dis.append((np.linalg.norm(shape[26]-shape[36])+np.linalg.norm(shape[37]-shape[47]))/2)\n",
    "    eye_widthDis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "eye_widthDis = np.array(eye_widthDis)\n",
    "eye_width = 0\n",
    "for i in range(len(rects)):\n",
    "    eye_width += eye_widthDis[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "eye_width = eye_width/len(rects)\n",
    "print(eye_width)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十六：眼睛高度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2737367544323206e-13\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为eye_height\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "each_eye_height = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    height = []\n",
    "    each_height=[]\n",
    "    l_eye_feature=[element for element in range(48,70)]\n",
    "    r_eye_feature=[element for element in range(26,48)]\n",
    "    l_eye_feature.remove(55)\n",
    "    l_eye_feature.remove(66)\n",
    "    r_eye_feature.remove(33)\n",
    "    r_eye_feature.remove(44)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        for i in range(14):\n",
    "            each_height.append(np.linalg.norm((shape[l_eye_feature[i]]-shape[l_eye_feature[-i-1]])))\n",
    "            each_height.append(np.linalg.norm((shape[r_eye_feature[i]]-shape[r_eye_feature[-i-1]])))\n",
    "        thickness.append(np.mean(each_height))\n",
    "        \n",
    "    each_eye_height.append(thickness)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "each_eye_height = np.array(each_eye_height)\n",
    "eye_height = 0\n",
    "for i in range(len(rects)):\n",
    "    eye_height += each_eye_height[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "eye_height = eye_height/len(rects)\n",
    "print(eye_height)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十七：鼻子中心到上唇中心的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3603228193684365\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为nose2lip\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "nose2lipDis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    up_lip_feature=[element for element in range(152,166)]+[element for element in range(180,194)]\n",
    "    nose_feature=[element for element in range(135,152)]\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        series_lip=[]\n",
    "        series_nose=[]\n",
    "        #找出眼睛的中心\n",
    "        for i in range(len(up_lip_feature)):\n",
    "            series_lip.append(shape[up_lip_feature[i]])\n",
    "        for i in range(len(nose_feature)):\n",
    "            series_nose.append(shape[nose_feature[i]])\n",
    "        series_lip=np.array(series_lip)\n",
    "        series_nose=np.array(series_nose)\n",
    "        up_lip_center=[(np.max(series_lip[:,0])+np.min(series_lip[:,0]))/2,(np.max(series_lip[:,1])+np.min(series_lip[:,1]))/2]\n",
    "        nose_center=[(np.max(series_nose[:,0])+np.min(series_nose[:,0]))/2,(np.max(series_nose[:,1])+np.min(series_nose[:,1]))/2]\n",
    "        up_lip_center=np.array(up_lip_center)\n",
    "        nose_center=np.array(nose_center)\n",
    "        dis.append(np.sqrt(np.sum((up_lip_center - nose_center) ** 2)))\n",
    "        \n",
    "    nose2lipDis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "nose2lipDis = np.array(nose2lipDis)\n",
    "nose2lip = 0\n",
    "for i in range(len(rects)):\n",
    "    nose2lip += nose2lipDis[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "nose2lip = nose2lip/len(rects)\n",
    "print(nose2lip)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征十八：下唇中心到下颚中心的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.563415487609097\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为lip2jaw\n",
    "cap = cv2.VideoCapture('C:/Users/balabalr/Documents/acxwigylke.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "lip2jawDis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    low_lip_feature=[element for element in range(11,26)]+[element for element in range(166,180)]\n",
    "    low_lip_feature.remove(22)\n",
    "    jaw_feature=[element for element in range(11)]+[21,32,43,54,65,76,87,98,109]+[element for element in range(114,135)]\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        series_lip=[]\n",
    "        series_jaw=[]\n",
    "        #找出眼睛的中心\n",
    "        for i in range(len(low_lip_feature)):\n",
    "            series_lip.append(shape[low_lip_feature[i]])\n",
    "        for i in range(len(jaw_feature)):\n",
    "            series_jaw.append(shape[jaw_feature[i]])\n",
    "        series_lip=np.array(series_lip)\n",
    "        series_jaw=np.array(series_jaw)\n",
    "        low_lip_center=[(np.max(series_lip[:,0])+np.min(series_lip[:,0]))/2,(np.max(series_lip[:,1])+np.min(series_lip[:,1]))/2]\n",
    "        jaw_center=[(np.max(series_jaw[:,0])+np.min(series_jaw[:,0]))/2,(np.max(series_jaw[:,1])+np.min(series_jaw[:,1]))/2]\n",
    "        low_lip_center=np.array(low_lip_center)\n",
    "        jaw_center=np.array(jaw_center)\n",
    "        dis.append(np.sqrt(np.sum((low_lip_center - jaw_center) ** 2)))\n",
    "    lip2jawDis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "lip2jawDis = np.array(lip2jawDis)\n",
    "lip2jaw = 0\n",
    "for i in range(len(rects)):\n",
    "    lip2jaw += lip2jawDis[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "lip2jaw = lip2jaw/len(rects)\n",
    "print(lip2jaw)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
