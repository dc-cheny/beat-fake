{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "p = \"shape_predictor_194_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征七：嘴唇颜色变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.277950837942434\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且嘴唇可以对应上,最终返回特征为lipcolorchg\n",
    "#三通道版本\n",
    "cap = cv2.VideoCapture('../data/aktnlyqpah.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#上下嘴唇对应点索引\n",
    "tlipindex = [i for i in range(152,166)]+[i for i in range(180,194)]\n",
    "blipindex = [i for i in range(11,21)]+[i for i in range(22,26)]+[i for i in range(166,180)]\n",
    "vlip = []\n",
    "for _ in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    lipavgs = []\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the image\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "        cv2.fillPoly(mask, [shape[tlipindex], shape[blipindex]], 1)\n",
    "        pixelcnt = mask.sum()\n",
    "        mask = mask.astype(np.bool)\n",
    "        out = np.zeros_like(image)\n",
    "        out[mask] = image[mask]\n",
    "        #计算嘴唇色度均值，rgb通道分开计算\n",
    "        lipsum = [out[:,:,i].sum() for i in range(3)]\n",
    "        lipavg = lipsum/pixelcnt\n",
    "        lipavg = lipavg.tolist()\n",
    "        lipavgs.append(lipavg)\n",
    "    vlip.append(lipavgs)\n",
    "\n",
    "#vlip为三维数组：[帧数，嘴唇数，rgb通道]\n",
    "# print(vlip)\n",
    "vlip = np.array(vlip)\n",
    "number = len(rects)\n",
    "lipcolorchg = []\n",
    "for m in range(number):\n",
    "    for n in range(3):\n",
    "        lipcolorchg.append(vlip[:,m,n].std())\n",
    "# print(lipcolorchg)    \n",
    "#计算所有嘴唇（一般只有一个嘴唇）的所有通道波动的均值\n",
    "lipcolorchg = np.array(lipcolorchg).mean()\n",
    "print(lipcolorchg) \n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1250843355574025\n"
     ]
    }
   ],
   "source": [
    "#灰度版本,返回特征为lipcolorchg\n",
    "cap = cv2.VideoCapture('../data/aktnlyqpah.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#上下嘴唇对应点索引\n",
    "tlipindex = [i for i in range(152,166)]+[i for i in range(180,194)]\n",
    "blipindex = [i for i in range(11,21)]+[i for i in range(22,26)]+[i for i in range(166,180)]\n",
    "vlip = []\n",
    "for _ in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    lipavgs = []\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the image\n",
    "        mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "        cv2.fillPoly(mask, [shape[tlipindex], shape[blipindex]], 1)\n",
    "        pixelcnt = mask.sum()\n",
    "        mask = mask.astype(np.bool)\n",
    "        out = np.zeros_like(gray)\n",
    "        out[mask] = gray[mask]\n",
    "        #计算嘴唇色度均值\n",
    "        lipsum = out.sum()\n",
    "        lipavg = lipsum/pixelcnt\n",
    "        lipavgs.append(lipavg)\n",
    "    vlip.append(lipavgs)\n",
    "\n",
    "#vlip为二维数组：[帧数，嘴唇数]\n",
    "\n",
    "vlip = np.array(vlip)\n",
    "number = len(rects)\n",
    "lipcolorchg = []\n",
    "for m in range(number):\n",
    "    lipcolorchg.append(vlip[:,m].std())\n",
    "    \n",
    "lipcolorchg = np.array(lipcolorchg).mean()\n",
    "print(lipcolorchg)\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征八：面部特征相对移动距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3974655197200074\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为fluctuation\n",
    "cap = cv2.VideoCapture('../data/aktnlyqpah.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#上下嘴唇对应点索引\n",
    "tlipindex = [i for i in range(152,166)]+[i for i in range(180,194)]\n",
    "blipindex = [i for i in range(11,21)]+[i for i in range(22,26)]+[i for i in range(166,180)]\n",
    "#眉毛对应点索引\n",
    "lbrowindex = [i for i in range(92,98)]+[i for i in range(99,109)]+[i for i in range(110,114)]\n",
    "rbrowindex = [i for i in range(70,76)]+[i for i in range(77,87)]+[i for i in range(88,92)]\n",
    "#眼睛对应点索引\n",
    "leyeindex = [i for i in range(48,54)]+[i for i in range(55,65)]+[i for i in range(66,70)]\n",
    "reyeindex = [i for i in range(26,32)]+[i for i in range(33,43)]+[i for i in range(44,48)]\n",
    "#鼻子对应点索引\n",
    "noseindex = [i for i in range(135,152)]\n",
    "    \n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    centers = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        #计算五官中心坐标\n",
    "        center = [shape[lbrowindex].mean(axis=0).tolist(),\n",
    "                  shape[rbrowindex].mean(axis=0).tolist(),\n",
    "                  shape[leyeindex].mean(axis=0).tolist(),\n",
    "                  shape[reyeindex].mean(axis=0).tolist(),\n",
    "                  shape[noseindex].mean(axis=0).tolist(),\n",
    "                  np.concatenate((shape[tlipindex],shape[blipindex])).mean(axis=0).tolist()]\n",
    "        \n",
    "        centers.append(center)\n",
    "    if f == 0:\n",
    "        base = centers.copy()\n",
    "        fluctuation = 0\n",
    "    else:\n",
    "        for i in range(len(rects)):\n",
    "            fluc = np.linalg.norm(np.array(centers[i])-np.array(base[i]),axis=1).std()\n",
    "            if fluc > fluctuation:\n",
    "                fluctuation = fluc\n",
    "#                 print(fluctuation)\n",
    "        base = centers.copy()\n",
    "print(fluctuation)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征九：眉毛间距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6508332669427084\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为browdis\n",
    "cap = cv2.VideoCapture('../data/aktnlyqpah.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "Dis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        dis.append(np.linalg.norm(shape[70]-shape[82]))\n",
    "        \n",
    "    Dis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "Dis = np.array(Dis)\n",
    "browdis = 0\n",
    "for i in range(len(rects)):\n",
    "    browdis += Dis[:,i].std()\n",
    "\n",
    "browdis = browdis/len(rects)\n",
    "print(browdis)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征十：眉毛中点到鼻子距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.694296661599912\n"
     ]
    }
   ],
   "source": [
    "#假设一个视频中人数恒定且相应人脸可以对应上,最终返回特征为brow2nose\n",
    "cap = cv2.VideoCapture('../data/aktnlyqpah.mp4')\n",
    "v_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "brow2noseDis = []\n",
    "for f in range(v_len):\n",
    "    _, image = cap.read()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "\n",
    "    # loop over the face detections\n",
    "    dis = []\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        dis.append(np.linalg.norm(np.concatenate((shape[70],shape[82])).mean(axis=0)-shape[143]))\n",
    "        \n",
    "    brow2noseDis.append(dis)\n",
    "#Dis为二维数组[帧数，脸数]\n",
    "brow2noseDis = np.array(brow2noseDis)\n",
    "brow2nose = 0\n",
    "for i in range(len(rects)):\n",
    "    brow2nose += brow2noseDis[:,i].std()\n",
    "#求几张脸该特征的均值\n",
    "brow2nose = brow2nose/len(rects)\n",
    "print(brow2nose)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
