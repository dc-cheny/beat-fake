{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import math\n",
    "import imutils\n",
    "import face_recognition\n",
    "\n",
    "from locations import landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing dlib's face detector and encoder, creating predictor\n",
    "p = \"../data/shape_predictor_194_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angle(v1, v2):\n",
    "    '''\n",
    "    计算两个向量的夹角：\n",
    "    AB = [5,-1,1,-3]\n",
    "    CD = [4,1,4.5,4.5]\n",
    "    print(angle_new(AB, CD),type(AB))\n",
    "    '''\n",
    "    dx1 = v1[2] - v1[0]\n",
    "    dy1 = v1[3] - v1[1]\n",
    "    dx2 = v2[2] - v2[0]\n",
    "    dy2 = v2[3] - v2[1]\n",
    "    angle1 = math.atan2(dy1, dx1)\n",
    "    angle1 = int(angle1 * 180/math.pi)\n",
    "    # print(angle1)\n",
    "    angle2 = math.atan2(dy2, dx2)\n",
    "    angle2 = int(angle2 * 180/math.pi)\n",
    "    # print(angle2)\n",
    "    if angle1*angle2 >= 0:\n",
    "        included_angle = abs(angle1-angle2)\n",
    "    else:\n",
    "        included_angle = abs(angle1) + abs(angle2)\n",
    "        if included_angle > 180:\n",
    "            included_angle = 360 - included_angle\n",
    "    return included_angle\n",
    "\n",
    "def calc_wuguan_std(center_list):\n",
    "    \"\"\"\n",
    "    输入一张脸在一个视频中的的五官中心点列表\n",
    "    \"\"\"\n",
    "    if len(center_list) == 1:\n",
    "        return np.array([0])\n",
    "    elif len(center_list) > 1:\n",
    "        return np.array([np.linalg.norm(np.array(center_list[i])-np.array(center_list[i+1]),axis=1).std() \\\n",
    "                for i in range(len(center_list)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc features\n",
    "def feature_calc(video_path, n_frames=30):\n",
    "    # Create video reader and find length\n",
    "    v_cap = cv2.VideoCapture(video_path)\n",
    "    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # pick n frames\n",
    "    sample = np.linspace(0, v_len - 1, n_frames).astype(int)\n",
    "\n",
    "    # by frame index\n",
    "    face_color_avgs = []\n",
    "    face_color_stds = []\n",
    "    yanpi_face_avgs = []\n",
    "    lip_color_avgs = []\n",
    "    face_fluctuation = []\n",
    "    brow_dists = []\n",
    "    brow2nose_dists = []\n",
    "    brow2eye_dists = []\n",
    "    brow2nose_angles = []\n",
    "    brow_thicks = []\n",
    "    face_rects = []\n",
    "    u_lip_thickness = []\n",
    "    d_lip_thickness = []\n",
    "    u_lip_width = []\n",
    "    d_lip_width = []\n",
    "    l_brow_length = []\n",
    "    r_brow_length = []\n",
    "    nose_width = []\n",
    "    l_eye_width = []\n",
    "    r_eye_width = []\n",
    "    l_eye_height = []\n",
    "    r_eye_height = []\n",
    "    nose2ulip_dists = []\n",
    "    xiaba2dlip_dists = []\n",
    "    nose_color_avgs = []\n",
    "    \n",
    "    \n",
    "    # part counter indexes\n",
    "    r_eye_index = landmarks().get_polygons_index('R_EYE')\n",
    "    l_eye_index = landmarks().get_polygons_index('L_EYE')\n",
    "    xiaba_index = landmarks().get_polygons_index('XIABA')\n",
    "    l_brow_index = landmarks().get_polygons_index('L_BROW')\n",
    "    r_brow_index = landmarks().get_polygons_index('R_BROW')\n",
    "    nose_index = landmarks().get_polygons_index('NOSE')\n",
    "    u_lip_index = landmarks().get_polygons_index('U_LIP')\n",
    "    d_lip_index = landmarks().get_polygons_index('D_LIP')\n",
    "    \n",
    "    latest_encodings = [] # init a list of the lastest encodings of each cluster of faces\n",
    "    flag = 0 # set a detector flag in one video while looping\n",
    "    \n",
    "    for j in range(v_len):\n",
    "        success = v_cap.grab()\n",
    "        if j in sample:\n",
    "#             print('=========第{}帧========'.format(j))\n",
    "            success, frame = v_cap.retrieve()\n",
    "            if not success:\n",
    "                continue\n",
    "            frame = imutils.resize(frame, width = int(frame.shape[1]/1.5))\n",
    "            \n",
    "            # detect faces in the grayscale image\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            rects = detector(gray, 0)\n",
    "            \n",
    "            # get encodings list of faces\n",
    "            known_face_locations = [(rect.top(), rect.right(), rect.bottom(), rect.left()) for rect in rects]\n",
    "            biden_encoding = face_recognition.face_encodings(face_image=frame, \n",
    "                                                             known_face_locations=known_face_locations)\n",
    "                        \n",
    "            for (i, rect) in enumerate(rects):\n",
    "                f_encoding = biden_encoding[i] # the encoding of i-th face\n",
    "                \n",
    "                # find the face index of this rect update latest_encodings list\n",
    "                if latest_encodings:\n",
    "                    results = face_recognition.compare_faces(latest_encodings, f_encoding)\n",
    "                    if sum(results) == 0:\n",
    "                        flag = 1\n",
    "                    else:\n",
    "                        true_index = results.index(True)\n",
    "                        latest_encodings[true_index] = f_encoding\n",
    "                else:\n",
    "                    flag = 1\n",
    "                \n",
    "                if flag:\n",
    "                    latest_encodings.append(f_encoding)\n",
    "                    true_index = len(latest_encodings) - 1\n",
    "                    face_color_avgs.append([])\n",
    "                    face_color_stds.append([])\n",
    "                    yanpi_face_avgs.append([])\n",
    "                    lip_color_avgs.append([])\n",
    "                    face_fluctuation.append([])\n",
    "                    brow_dists.append([])\n",
    "                    brow2nose_dists.append([])\n",
    "                    brow2eye_dists.append([])\n",
    "                    brow2nose_angles.append([[],[]])\n",
    "                    brow_thicks.append([])\n",
    "                    face_rects.append([])\n",
    "                    u_lip_thickness.append([])\n",
    "                    d_lip_thickness.append([])\n",
    "                    u_lip_width.append([])\n",
    "                    d_lip_width.append([])\n",
    "                    l_brow_length.append([])\n",
    "                    r_brow_length.append([])\n",
    "                    nose_width.append([])\n",
    "                    l_eye_width.append([])\n",
    "                    r_eye_width.append([])\n",
    "                    l_eye_height.append([])\n",
    "                    r_eye_height.append([])\n",
    "                    nose2ulip_dists.append([])\n",
    "                    xiaba2dlip_dists.append([])\n",
    "                    nose_color_avgs.append([])\n",
    "                    \n",
    "                    flag = 0\n",
    "                \n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                xia_lian = abs(shape[0][1] - shape[109][1])\n",
    "                to_append_pnt = [[shape[0][0], int(shape[0][1] + xia_lian * 0.4)], \n",
    "                                   [shape[134][0], int(shape[134][1] + xia_lian * 0.4)]]\n",
    "\n",
    "                # part counter points\n",
    "                l_eye = shape[l_eye_index]\n",
    "                r_eye = shape[r_eye_index]\n",
    "                xiaba = np.concatenate((shape[xiaba_index], to_append_pnt), axis=0)\n",
    "                u_lip = shape[u_lip_index]\n",
    "                d_lip = shape[d_lip_index]\n",
    "                l_brow = shape[l_brow_index]\n",
    "                r_brow = shape[r_brow_index]\n",
    "                nose = shape[nose_index]\n",
    "\n",
    "                # make masks with coordinates\n",
    "                mask_xiaba = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "                mask_eye = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "                mask_lip = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "                mask_nose = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "\n",
    "                cv2.fillPoly(mask_xiaba, [xiaba], 1)\n",
    "                cv2.fillPoly(mask_eye, [l_eye, r_eye], 1)\n",
    "                cv2.fillPoly(mask_lip, [u_lip, d_lip], 1)\n",
    "                cv2.fillPoly(mask_nose, [nose], 1)\n",
    "\n",
    "                mask_xiaba = mask_xiaba.astype(np.bool)\n",
    "                xiaba_out = np.zeros_like(gray)\n",
    "                xiaba_out[mask_xiaba] = gray[mask_xiaba]\n",
    "                mask_eye = mask_eye.astype(np.bool)\n",
    "                eye_out = np.zeros_like(gray)\n",
    "                eye_out[mask_eye] = gray[mask_eye]\n",
    "                mask_lip = mask_lip.astype(np.bool)\n",
    "                lip_out = np.zeros_like(gray)\n",
    "                lip_out[mask_lip] = gray[mask_lip]\n",
    "                mask_nose = mask_nose.astype(np.bool)\n",
    "                nose_out = np.zeros_like(gray)\n",
    "                nose_out[mask_nose] = gray[mask_nose]\n",
    "\n",
    "                l_x, l_y, l_w, l_h = cv2.boundingRect(l_eye)\n",
    "                l_eye_rectangle = gray[int(l_y-0.25*l_h):l_y+l_h, l_x:l_x+l_w]\n",
    "                r_x, r_y, r_w, r_h = cv2.boundingRect(r_eye)\n",
    "                r_eye_rectangle = gray[int(r_y-0.25*r_h):r_y+r_h, r_x:r_x+r_w]\n",
    "\n",
    "                # distances\n",
    "                center = [l_brow.mean(axis=0).tolist(),\n",
    "                          r_brow.mean(axis=0).tolist(),\n",
    "                          l_eye.mean(axis=0).tolist(),\n",
    "                          r_eye.mean(axis=0).tolist(),\n",
    "                          nose.mean(axis=0).tolist(),\n",
    "                          np.concatenate((u_lip,d_lip)).mean(axis=0).tolist()]\n",
    "                brow_dist = np.linalg.norm(shape[70] - shape[82])\n",
    "                brow2nose_dist = np.linalg.norm(np.concatenate((shape[70],shape[82])).mean(axis=0) - shape[143])\n",
    "                brow2eye_dist = (np.linalg.norm(np.array(center[0])-np.array(center[2])) + np.linalg.norm(np.array(center[1])-np.array(center[3]))) / 2\n",
    "                brow_thick = (np.linalg.norm(shape[96] - shape[110]) + np.linalg.norm(shape[74] - shape[88])) / 2\n",
    "                u_lip_dist = np.linalg.norm(shape[159] - shape[187])\n",
    "                d_lip_dist = np.linalg.norm(shape[19] - shape[174])\n",
    "                u_lip_width_dist = np.linalg.norm(shape[152] - shape[165])\n",
    "                d_lip_width_dist = np.linalg.norm(shape[25] - shape[11])\n",
    "                l_brow_len_dist = np.linalg.norm(shape[103] - shape[92])\n",
    "                r_brow_len_dist = np.linalg.norm(shape[70] - shape[81])\n",
    "                nose_width_dist = np.linalg.norm(shape[139] - shape[147])\n",
    "                l_eye_width_dist = np.linalg.norm(shape[59] - shape[48])\n",
    "                r_eye_width_dist = np.linalg.norm(shape[26] - shape[38])\n",
    "                l_eye_height_dist = np.linalg.norm(shape[55] - shape[64])\n",
    "                r_eye_height_dist = np.linalg.norm(shape[31] - shape[44])\n",
    "                nose2ulip_dist = np.linalg.norm(nose.mean(axis=0) - u_lip.mean(axis=0))\n",
    "                xiaba2dlip_dist = np.linalg.norm(shape[xiaba_index].mean(axis=0) - d_lip.mean(axis=0))\n",
    "\n",
    "                # angles\n",
    "                nose_vec = np.array([shape[139], shape[147]]).mean(axis=0).tolist() + np.array([shape[135], shape[151]]).mean(axis=0).tolist()\n",
    "                l_brow_vec = shape[103].tolist() + shape[113].tolist()\n",
    "                r_brow_vec = shape[81].tolist() + shape[91].tolist()\n",
    "                l_brow2nose_angle = calc_angle(nose_vec, l_brow_vec)\n",
    "                r_brow2nose_angle = calc_angle(nose_vec, r_brow_vec)\n",
    "\n",
    "\n",
    "                # calc feature and drop them into corresponding face index\n",
    "                face_color_avg = xiaba_out.sum() / mask_xiaba.sum()\n",
    "                face_color_avgs[true_index].append(face_color_avg)\n",
    "                face_color_stds[true_index].append(xiaba_out.std())\n",
    "                yanpi_avg = (l_eye_rectangle.sum() + r_eye_rectangle.sum() - eye_out.sum()) / ((l_eye_rectangle.shape[0] + \\\n",
    "                        r_eye_rectangle.shape[0]) * (l_eye_rectangle.shape[1] + r_eye_rectangle.shape[1]) - mask_eye.sum())\n",
    "                yanpi_face_avgs[true_index].append(yanpi_avg)\n",
    "                lip_color_avg = lip_out.sum() / mask_lip.sum()\n",
    "                lip_color_avgs[true_index].append(lip_color_avg)\n",
    "                face_fluctuation[true_index].append(center)\n",
    "                brow_dists[true_index].append(brow_dist)\n",
    "                brow2nose_dists[true_index].append(brow2nose_dist)\n",
    "                brow2eye_dists[true_index].append(brow2eye_dist)\n",
    "                brow2nose_angles[true_index][0].append(l_brow2nose_angle)\n",
    "                brow2nose_angles[true_index][1].append(r_brow2nose_angle)\n",
    "                brow_thicks[true_index].append(brow_thick)\n",
    "                u_lip_thickness[true_index].append(u_lip_dist)\n",
    "                d_lip_thickness[true_index].append(d_lip_dist)\n",
    "                u_lip_width[true_index].append(u_lip_width_dist)\n",
    "                d_lip_width[true_index].append(d_lip_width_dist)\n",
    "                l_brow_length[true_index].append(l_brow_len_dist)\n",
    "                r_brow_length[true_index].append(r_brow_len_dist)\n",
    "                nose_width[true_index].append(nose_width_dist)\n",
    "                l_eye_width[true_index].append(l_eye_width_dist)\n",
    "                r_eye_width[true_index].append(r_eye_width_dist)\n",
    "                l_eye_height[true_index].append(l_eye_height_dist)\n",
    "                r_eye_height[true_index].append(r_eye_height_dist)\n",
    "                nose2ulip_dists[true_index].append(nose2ulip_dist)\n",
    "                xiaba2dlip_dists[true_index].append(xiaba2dlip_dist)\n",
    "                nose_color_avg = nose_out.sum() / mask_nose.sum()\n",
    "                nose_color_avgs[true_index].append(nose_color_avg)\n",
    "                face_rects[true_index].append(rect.left())\n",
    "\n",
    "    v_cap.release() # release video\n",
    "    \n",
    "    face_cnt = len(face_color_avgs) # 脸的数量\n",
    "    feature_face_color = [[np.array(face_color_avgs[i]).std()] for i in range(face_cnt)] # 面部色度标准差\n",
    "    feature_face_maxdiff = [[max(face_color_stds[i])] for i in range(face_cnt)] # 面部色度最大差异（最大标准差）\n",
    "    feature_yanpi_face_diff = [[np.array(yanpi_face_avgs[i]).std()] for i in range(face_cnt)] # 眼皮面部色度差的标准差\n",
    "    feature_lip_color = [[np.array(lip_color_avgs[i]).std()] for i in range(face_cnt)] # 嘴唇色度标准差\n",
    "    feature_face_fluctuation = [[max(calc_wuguan_std(face_fluctuation[i]))] for i in range(face_cnt)] # 面部特征移动相对距离\n",
    "    feature_brow_dist = [[np.array(brow_dists[i]).std()] for i in range(face_cnt)] # 眉毛距离标准差\n",
    "    feature_brow2nose_dist = [[np.array(brow2nose_dists[i]).std()] for i in range(face_cnt)] # 眉心到鼻尖距离标准差\n",
    "    feature_brow2eye_dist = [[np.array(brow2eye_dists[i]).std()] for i in range(face_cnt)] # 眉毛到眼睛距离标准差\n",
    "    feature_brow2nose_angle = [[np.array(brow2nose_angles[i][0]).std(),np.array(brow2nose_angles[i][1]).std()] \n",
    "                               for i in range(face_cnt)] # 眉毛与鼻子夹角，左右眉毛都做了计算\n",
    "    feature_brow_thick = [[np.array(brow_thicks[i]).std()] for i in range(face_cnt)] # 眉毛粗细\n",
    "    feature_ulip_thickness = [[np.array(u_lip_thickness[i]).std()] for i in range(face_cnt)] # 上嘴唇厚度标准差\n",
    "    feature_dlip_thickness = [[np.array(d_lip_thickness[i]).std()] for i in range(face_cnt)] # 下嘴唇厚度标准差\n",
    "    feature_ulip_width = [[np.array(u_lip_width[i]).std()] for i in range(face_cnt)] # 上嘴唇宽度标准差\n",
    "    feature_dlip_width = [[np.array(d_lip_width[i]).std()] for i in range(face_cnt)] # 下嘴唇宽度标准差\n",
    "    feature_lbrow_len = [[np.array(l_brow_length[i]).std()] for i in range(face_cnt)] # 上眉毛长度标准差\n",
    "    feature_rbrow_len = [[np.array(r_brow_length[i]).std()] for i in range(face_cnt)] # 下眉毛长度标准差\n",
    "    feature_nose_width = [[np.array(nose_width[i]).std()] for i in range(face_cnt)] # 鼻子宽度标准差\n",
    "    feature_leye_width = [[np.array(l_eye_width[i]).std()] for i in range(face_cnt)] # 左眼宽度标准差\n",
    "    feature_reye_width = [[np.array(r_eye_width[i]).std()] for i in range(face_cnt)] # 右眼宽度标准差\n",
    "    feature_leye_height = [[np.array(l_eye_height[i]).std()] for i in range(face_cnt)] # 左眼高度标准差\n",
    "    feature_reye_height = [[np.array(r_eye_height[i]).std()] for i in range(face_cnt)] # 右眼高度标准差\n",
    "    feature_nose2ulip_dist = [[np.array(nose2ulip_dists[i]).std()] for i in range(face_cnt)] # 鼻子中心到上唇中心的距离标准差\n",
    "    feature_xiaba2dlip_dist = [[np.array(xiaba2dlip_dists[i]).std()] for i in range(face_cnt)] # 下唇中心到下颚中心的距离标准差\n",
    "    feature_nose_color = [[np.array(nose_color_avgs[i]).std()] for i in range(face_cnt)] # 鼻子区域的颜色标准差\n",
    "    \n",
    "    rect_left = [[np.array(face_rects[i]).mean()] for i in range(face_cnt)] # 计算每张脸与左边框的距离，以此来打标签\n",
    "\n",
    "    feature = []\n",
    "    for i in range(face_cnt):\n",
    "        feature.append(feature_face_color[i] +\n",
    "                       feature_face_maxdiff[i] +\n",
    "                       feature_yanpi_face_diff[i] +\n",
    "                       feature_lip_color[i] +\n",
    "                       feature_face_fluctuation[i] + \n",
    "                       feature_brow_dist[i] + \n",
    "                       feature_brow2nose_dist[i] +\n",
    "                       feature_brow2eye_dist[i] +\n",
    "                       feature_brow2nose_angle[i] +\n",
    "                       feature_brow_thick[i] + \n",
    "                       feature_ulip_thickness[i] + \n",
    "                       feature_dlip_thickness[i] + \n",
    "                       feature_ulip_width[i] + \n",
    "                       feature_dlip_width[i] + \n",
    "                       feature_lbrow_len[i] + \n",
    "                       feature_rbrow_len[i] + \n",
    "                       feature_nose_width[i] + \n",
    "                       feature_leye_width[i] + \n",
    "                       feature_reye_width[i] + \n",
    "                       feature_leye_height[i] + \n",
    "                       feature_reye_height[i] + \n",
    "                       feature_nose2ulip_dist[i] + \n",
    "                       feature_xiaba2dlip_dist[i] + \n",
    "                       feature_nose_color[i] + \n",
    "                       rect_left[i])\n",
    "    print(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    return feature_calc('../data/exbxfmqqpx.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.9528528821054545, 4.9891731774863946, 0.8805247890338259, 4.186178717744759, 6.132510285414462, 2.4974263964762273, 7.873342167384229, 1.8648729108092956, 2.8973363324145254, 3.048363004434138, 0.49287265138035974, 0.5661290467125353, 0.7076418763172199, 2.723017973112768, 2.0895342526337957, 3.094565500243091, 2.6292673104584403, 1.140423063681016, 1.0943632433096537, 1.6550155651693033, 0.9046750748700084, 0.9746464120370437, 1.2516412767270821, 4.307534649508412, 3.9471592534362108, 833.4761904761905], [0.0, 7.9334629969536214, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 233.0]]\n",
      "5.789464950561523\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "main()\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "def calc_folder(folder_num):\n",
    "    cnt = 0\n",
    "    out_path = \"/home/sufedc_nvidia_handianyouhua/deep_fake/results/\"\n",
    "    data_path = \"/home/sufedc_nvidia_handianyouhua/deep_fake/data/data/\"\n",
    "    metadata = json.loads(open(os.path.join(data_path, 'dfdc_train_part_{}'.format(folder_num), 'metadata.json')).read())\n",
    "    features = []\n",
    "    t1 = time.time()\n",
    "\n",
    "    for video in metadata.keys():\n",
    "        if cnt % 20 == 0:\n",
    "            print('============{} FINISHED, {}min used========='.format(cnt, (time.time()-t1) / 60.0))   \n",
    "        cnt += 1\n",
    "        video_path = os.path.join(data_path, 'dfdc_train_part_{}'.format(folder_num), video)\n",
    "        print(video)\n",
    "        if os.path.exists(video_path):\n",
    "            if metadata[video]['label'] == 'FAKE':\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "            feature = feature_calc(video_path, n_frames=20)\n",
    "            if feature != []:\n",
    "                for i in range(len(feature)):\n",
    "                    features.append([video] + feature[i] + [label])\n",
    "\n",
    "    res = pd.DataFrame(features,columns = ['video',\n",
    "                                           'face_color',\n",
    "                                           'face_maxdiff',\n",
    "                                           'yanpi_face_diff',\n",
    "                                           'lip_color',\n",
    "                                           'face_fluctuation',\n",
    "                                           'brow_dist',\n",
    "                                           'brow2nose_dist',\n",
    "                                           'brow2eye_dist',\n",
    "                                           'l_brow2nose_angle',\n",
    "                                           'r_brow2nose_angle',\n",
    "                                           'brow_thick',\n",
    "                                           'ulip_thickness',\n",
    "                                           'dlip_thickness',\n",
    "                                           'ulip_width',\n",
    "                                           'dlip_width',\n",
    "                                           'lbrow_len',\n",
    "                                           'rbrow_len',\n",
    "                                           'nose_width',\n",
    "                                           'leye_width',\n",
    "                                           'reye_width',\n",
    "                                           'leye_height',\n",
    "                                           'reye_height',\n",
    "                                           'nose2ulip_dist',\n",
    "                                           'xiaba2dlip_dist',\n",
    "                                           'nose_color',\n",
    "                                           'rect_left',\n",
    "                                           'label'])\n",
    "\n",
    "    res.to_csv(out_path+'dfdc_train_part_{}.csv'.format(folder_num), sep=',', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
