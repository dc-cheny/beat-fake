{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import math\n",
    "import imutils\n",
    "import face_recognition\n",
    "\n",
    "from locations import landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing dlib's face detector and encoder, creating predictor\n",
    "p = \"../data/shape_predictor_194_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_angle(v1, v2):\n",
    "    '''\n",
    "    计算两个向量的夹角：\n",
    "    AB = [5,-1,1,-3]\n",
    "    CD = [4,1,4.5,4.5]\n",
    "    print(angle_new(AB, CD),type(AB))\n",
    "    '''\n",
    "    dx1 = v1[2] - v1[0]\n",
    "    dy1 = v1[3] - v1[1]\n",
    "    dx2 = v2[2] - v2[0]\n",
    "    dy2 = v2[3] - v2[1]\n",
    "    angle1 = math.atan2(dy1, dx1)\n",
    "    angle1 = int(angle1 * 180/math.pi)\n",
    "    # print(angle1)\n",
    "    angle2 = math.atan2(dy2, dx2)\n",
    "    angle2 = int(angle2 * 180/math.pi)\n",
    "    # print(angle2)\n",
    "    if angle1*angle2 >= 0:\n",
    "        included_angle = abs(angle1-angle2)\n",
    "    else:\n",
    "        included_angle = abs(angle1) + abs(angle2)\n",
    "        if included_angle > 180:\n",
    "            included_angle = 360 - included_angle\n",
    "    return included_angle\n",
    "\n",
    "def calc_wuguan_std(center_list):\n",
    "    \"\"\"\n",
    "    输入一张脸在一个视频中的的五官中心点列表\n",
    "    \"\"\"\n",
    "    if len(center_list) == 1:\n",
    "        return np.array([0])\n",
    "    elif len(center_list) > 1:\n",
    "        return np.array([np.linalg.norm(np.array(center_list[i])-np.array(center_list[i+1]),axis=1).std() \\\n",
    "                for i in range(len(center_list)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc features\n",
    "def feature_calc(video_path, n_frames=30):\n",
    "    # Create video reader and find length\n",
    "    v_cap = cv2.VideoCapture(video_path)\n",
    "    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # pick n frames\n",
    "    sample = np.linspace(0, v_len - 1, n_frames).astype(int)\n",
    "\n",
    "    # by frame index\n",
    "    face_color_avgs = []\n",
    "    face_color_stds = []\n",
    "    yanpi_face_avgs = []\n",
    "    lip_color_avgs = []\n",
    "    face_fluctuation = []\n",
    "    brow_dists = []\n",
    "    brow2nose_dists = []\n",
    "    brow2eye_dists = []\n",
    "    brow2nose_angles = []\n",
    "    brow_thicks = []\n",
    "    face_rects = []\n",
    "\n",
    "    # part counter indexes\n",
    "    r_eye_index = landmarks().get_polygons_index('R_EYE')\n",
    "    l_eye_index = landmarks().get_polygons_index('L_EYE')\n",
    "    xiaba_index = landmarks().get_polygons_index('XIABA')\n",
    "    l_brow_index = landmarks().get_polygons_index('L_BROW')\n",
    "    r_brow_index = landmarks().get_polygons_index('R_BROW')\n",
    "    nose_index = landmarks().get_polygons_index('NOSE')\n",
    "    u_lip_index = landmarks().get_polygons_index('U_LIP')\n",
    "    d_lip_index = landmarks().get_polygons_index('D_LIP')\n",
    "    \n",
    "    latest_encodings = [] # init a list of the lastest encodings of each cluster of faces\n",
    "    flag = 0 # set a detector flag in one video while looping\n",
    "    \n",
    "    for j in range(v_len):\n",
    "        success = v_cap.grab()\n",
    "        if j in sample:\n",
    "#             print('=========第{}帧========'.format(j))\n",
    "            success, frame = v_cap.retrieve()\n",
    "            if not success:\n",
    "                continue\n",
    "            frame = imutils.resize(frame, width = 1000)\n",
    "            \n",
    "            # detect faces in the grayscale image\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            rects = detector(gray, 0)\n",
    "            \n",
    "            # get encodings list of faces\n",
    "            known_face_locations = [(rect.top(), rect.right(), rect.bottom(), rect.left()) for rect in rects]\n",
    "            biden_encoding = face_recognition.face_encodings(face_image=frame, \n",
    "                                                             known_face_locations=known_face_locations)\n",
    "                        \n",
    "            for (i, rect) in enumerate(rects):\n",
    "                f_encoding = biden_encoding[i] # the encoding of i-th face\n",
    "                \n",
    "                # find the face index of this rect update latest_encodings list\n",
    "                if latest_encodings:\n",
    "                    results = face_recognition.compare_faces(latest_encodings, f_encoding)\n",
    "                    if sum(results) == 0:\n",
    "                        flag = 1\n",
    "                    else:\n",
    "                        true_index = results.index(True)\n",
    "                        latest_encodings[true_index] = f_encoding\n",
    "                else:\n",
    "                    flag = 1\n",
    "                \n",
    "                if flag:\n",
    "                    latest_encodings.append(f_encoding)\n",
    "                    true_index = len(latest_encodings) - 1\n",
    "                    face_color_avgs.append([])\n",
    "                    face_color_stds.append([])\n",
    "                    yanpi_face_avgs.append([])\n",
    "                    lip_color_avgs.append([])\n",
    "                    face_fluctuation.append([])\n",
    "                    brow_dists.append([])\n",
    "                    brow2nose_dists.append([])\n",
    "                    brow2eye_dists.append([])\n",
    "                    brow2nose_angles.append([[],[]])\n",
    "                    brow_thicks.append([])\n",
    "                    face_rects.append([])\n",
    "                    flag = 0\n",
    "                \n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "                    \n",
    "                xia_lian = abs(shape[0][1] - shape[109][1])\n",
    "                to_append_pnt = [[shape[0][0], int(shape[0][1] + xia_lian * 0.4)], \n",
    "                                   [shape[134][0], int(shape[134][1] + xia_lian * 0.4)]]\n",
    "\n",
    "                # part counter points\n",
    "                l_eye = shape[l_eye_index]\n",
    "                r_eye = shape[r_eye_index]\n",
    "                xiaba = np.concatenate((shape[xiaba_index], to_append_pnt), axis=0)\n",
    "                u_lip = shape[u_lip_index]\n",
    "                d_lip = shape[d_lip_index]\n",
    "                l_brow = shape[l_brow_index]\n",
    "                r_brow = shape[r_brow_index]\n",
    "                nose = shape[nose_index]\n",
    "\n",
    "                # make masks with coordinates\n",
    "                mask_xiaba = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "                mask_eye = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "                mask_lip = np.zeros((frame.shape[0], frame.shape[1]))\n",
    "\n",
    "                cv2.fillPoly(mask_xiaba, [xiaba], 1)\n",
    "                cv2.fillPoly(mask_eye, [l_eye, r_eye], 1)\n",
    "                cv2.fillPoly(mask_lip, [u_lip, d_lip], 1)\n",
    "\n",
    "                mask_xiaba = mask_xiaba.astype(np.bool)\n",
    "                xiaba_out = np.zeros_like(gray)\n",
    "                xiaba_out[mask_xiaba] = gray[mask_xiaba]\n",
    "                mask_eye = mask_eye.astype(np.bool)\n",
    "                eye_out = np.zeros_like(gray)\n",
    "                eye_out[mask_eye] = gray[mask_eye]\n",
    "                mask_lip = mask_lip.astype(np.bool)\n",
    "                lip_out = np.zeros_like(gray)\n",
    "                lip_out[mask_lip] = gray[mask_lip]\n",
    "\n",
    "                l_x, l_y, l_w, l_h = cv2.boundingRect(l_eye)\n",
    "                l_eye_rectangle = gray[int(l_y-0.25*l_h):l_y+l_h, l_x:l_x+l_w]\n",
    "                r_x, r_y, r_w, r_h = cv2.boundingRect(r_eye)\n",
    "                r_eye_rectangle = gray[int(r_y-0.25*r_h):r_y+r_h, r_x:r_x+r_w]\n",
    "\n",
    "                # distances\n",
    "                center = [l_brow.mean(axis=0).tolist(),\n",
    "                          r_brow.mean(axis=0).tolist(),\n",
    "                          l_eye.mean(axis=0).tolist(),\n",
    "                          r_eye.mean(axis=0).tolist(),\n",
    "                          nose.mean(axis=0).tolist(),\n",
    "                          np.concatenate((u_lip,d_lip)).mean(axis=0).tolist()]\n",
    "                brow_dist = np.linalg.norm(shape[70] - shape[82])\n",
    "                brow2nose_dist = np.linalg.norm(np.concatenate((shape[70],shape[82])).mean(axis=0) - shape[143])\n",
    "                brow2eye_dist = (np.linalg.norm(np.array(center[0])-np.array(center[2])) + np.linalg.norm(np.array(center[1])-np.array(center[3]))) / 2\n",
    "                brow_thick = (np.linalg.norm(shape[96] - shape[110]) + np.linalg.norm(shape[74] - shape[88])) / 2\n",
    "\n",
    "                # angels\n",
    "                nose_vec = np.array([shape[139],shape[147]]).mean(axis=0).tolist() + np.array([shape[135],shape[151]]).mean(axis=0).tolist()\n",
    "                l_brow_vec = shape[103].tolist() + shape[113].tolist()\n",
    "                r_brow_vec = shape[81].tolist() + shape[91].tolist()\n",
    "                l_brow2nose_angel = calc_angle(nose_vec,l_brow_vec)\n",
    "                r_brow2nose_angel = calc_angle(nose_vec,r_brow_vec)\n",
    "\n",
    "\n",
    "                # calc feature and drop them into corresponding face index\n",
    "                face_color_avg = xiaba_out.sum() / mask_xiaba.sum()\n",
    "                face_color_avgs[true_index].append(face_color_avg)\n",
    "                face_color_stds[true_index].append(xiaba_out.std())\n",
    "                yanpi_avg = (l_eye_rectangle.sum() + r_eye_rectangle.sum() - eye_out.sum()) / ((l_eye_rectangle.shape[0] + \\\n",
    "                        r_eye_rectangle.shape[0]) * (l_eye_rectangle.shape[1] + r_eye_rectangle.shape[1]) - mask_eye.sum())\n",
    "                yanpi_face_avgs[true_index].append(yanpi_avg)\n",
    "                lip_color_avg = lip_out.sum() / mask_lip.sum()\n",
    "                lip_color_avgs[true_index].append(lip_color_avg)\n",
    "                face_fluctuation[true_index].append(center)\n",
    "                brow_dists[true_index].append(brow_dist)\n",
    "                brow2nose_dists[true_index].append(brow2nose_dist)\n",
    "                brow2eye_dists[true_index].append(brow2eye_dist)\n",
    "                brow2nose_angles[true_index][0].append(l_brow2nose_angel)\n",
    "                brow2nose_angles[true_index][1].append(r_brow2nose_angel)\n",
    "                brow_thicks[true_index].append(brow_thick)\n",
    "                face_rects[true_index].append(rect.left())\n",
    "\n",
    "    v_cap.release() # release video\n",
    "    \n",
    "    face_cnt = len(face_color_avgs) # 脸的数量\n",
    "    feature_face_color = [[np.array(face_color_avgs[i]).std()] for i in range(face_cnt)] # 面部色度标准差\n",
    "    feature_face_maxdiff = [[max(face_color_stds[i])] for i in range(face_cnt)] # 面部色度最大差异（最大标准差）\n",
    "    feature_yanpi_face_diff = [[np.array(yanpi_face_avgs[i]).std()] for i in range(face_cnt)] # 眼皮面部色度差的标准差\n",
    "    feature_lip_color = [[np.array(lip_color_avgs[i]).std()] for i in range(face_cnt)] # 嘴唇色度标准差\n",
    "    feature_face_fluctuation = [[max(calc_wuguan_std(face_fluctuation[i]))] for i in range(face_cnt)] # 面部特征移动相对距离\n",
    "    feature_brow_dist = [[np.array(brow_dists[i]).std()] for i in range(face_cnt)] # 眉毛距离标准差\n",
    "    feature_brow2nose_dist = [[np.array(brow2nose_dists[i]).std()] for i in range(face_cnt)] # 眉心到鼻尖距离标准差\n",
    "    feature_brow2eye_dist = [[np.array(brow2eye_dists[i]).std()] for i in range(face_cnt)] # 眉毛到眼睛距离标准差\n",
    "    feature_brow2nose_angle = [[np.array(brow2nose_angles[i][0]).std(),np.array(brow2nose_angles[i][1]).std()] \n",
    "                               for i in range(face_cnt)] # 眉毛与鼻子夹角，左右眉毛都做了计算\n",
    "    feature_brow_thick = [[np.array(brow_thicks[i]).std()] for i in range(face_cnt)] # 眉毛粗细\n",
    "    rect_left = [[np.array(face_rects[i]).mean()] for i in range(face_cnt)] # 计算每张脸与左边框的距离，以此来打标签\n",
    "\n",
    "    feature = []\n",
    "    for i in range(face_cnt):\n",
    "        feature.append(feature_face_color[i] +\n",
    "                       feature_face_maxdiff[i] +\n",
    "                       feature_yanpi_face_diff[i] +\n",
    "                       feature_lip_color[i] +\n",
    "                       feature_face_fluctuation[i] +\n",
    "                      feature_brow_dist[i] +\n",
    "                      feature_brow2nose_dist[i] +\n",
    "                      feature_brow2eye_dist[i] +\n",
    "                      feature_brow2nose_angle[i] +\n",
    "                      feature_brow_thick[i] + \n",
    "                      rect_left[i])\n",
    "    print(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    return feature_calc('../data/exbxfmqqpx.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.146701306650596, 5.021132139396925, 1.1200151690175546, 4.762820441642136, 3.8737907586797324, 2.1723619695792027, 6.842880249126811, 0.9643196159810988, 3.103250761581506, 2.372796933843307, 0.5015199231916689, 654.0909090909091], [0.0, 7.874720743840239, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 194.0]]\n",
      "3.948089122772217\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "main()\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "metadata = json.loads(open('./data/metadata.json').read())\n",
    "features = []\n",
    "for video in metadata.keys():\n",
    "    for k in range(10):\n",
    "        if os.path.exists(os.path.join('./data/dfdc_train_part_{}'.format(k),video)):\n",
    "            video_path = os.path.join('./data/dfdc_train_part_{}'.format(k),video)\n",
    "            if metadata[video]['label'] == 'FAKE':\n",
    "                label = 0\n",
    "            else:\n",
    "                label = 1\n",
    "            feature = feature_calc(video_path)\n",
    "            if feature:\n",
    "                for i in range(len(feature)):\n",
    "                    features.append([video] + feature[i] + [label])\n",
    "                    print([video] + feature[i] + [label])\n",
    "        break\n",
    "                    \n",
    "res = pd.DataFrame(features,columns = ['video',\n",
    "                                       'face_color',\n",
    "                                       'face_maxdiff',\n",
    "                                       'yanpi_face_diff',\n",
    "                                       'lip_color',\n",
    "                                       'face_fluctuation',\n",
    "                                       'brow_dist',\n",
    "                                       'brow2nose_dist',\n",
    "                                       'brow2eye_dist',\n",
    "                                       'l_brow2nose_angle',\n",
    "                                       'r_brow2nose_angle',\n",
    "                                       'brow_thick',\n",
    "                                       'label'])\n",
    "\n",
    "# outpath = '../feature.csv'\n",
    "# df.to_csv(outputpath,sep=',',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
